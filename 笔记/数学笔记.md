# 笔记

##  线性代数

###  特征值和秩的关系

**特征值的个数** 与矩阵的阶数 **（矩阵的维度）** 相关，而与矩阵的秩无直接关系。

#### 1. **特征值的个数与矩阵的阶数相关：**

- 对于一个 $n \times n$ 的矩阵 $A$，它的特征值的个数最多是 $n$ 个（包括重根）。这是因为矩阵的特征多项式是一个次数为 $n$ 的多项式，而一个多项式的根的个数（包括重根）等于其次数。所以特征值的个数的上限是矩阵的阶数。
- 特征值的个数可能少于 $n$，这取决于矩阵的特性（例如，是否存在重复的特征值，或者矩阵是否有缺失的特征值等）。

#### 2. **特征值的个数与秩的关系：**

- **秩** 与 **特征值的个数** 没有直接的关系。秩是衡量矩阵中线性独立行（或列）个数的指标，它告诉我们矩阵的线性独立性。
- 特征值的个数与矩阵是否可逆、是否是满秩矩阵相关，但并不是秩的直接函数。

#### 3. **特征值与秩的关系：**

- 如果一个矩阵的秩为 $r$，它有 $n - r$ 个零特征值。也就是说，矩阵的秩决定了有多少个零特征值，但不决定非零特征值的数量。
- 若矩阵是满秩矩阵（秩为 $n$，即 $A$ 是可逆的），则它的特征值不包含零。

#### 4. **总结：**

- **特征值的个数**：与矩阵的阶数（$n \times n$矩阵的特征值个数最多为 $n$）相关。
- **秩**：影响矩阵是否有零特征值，但不直接影响特征值的总个数。



###  特征向量和特征值的关系

一个特征值对应一个特征向量，不同特征值的特征向量线性无关，一个多重特征值的多个特征向量可能相关也可能不相关

###  特征值小点

同一特征值的特征向量可以组合，不同特征值的特征向量不能组合

特征向量是构成解（基础解系）的自由量，多个

上三角的主对角线元素就是他的特征值！

抽象型矩阵一般带入A！特征值！两步

###  相似理论

P可以同时相似化于A，B则

必要条件：AB=BA

充分条件：AB=BA，A有n个不同特征值

**相似结论**

相似有一个重要结论就是如果P的逆*A*P=B，则A，B相似.A ,B特征值如果相同且B可以相似对角化，则A，B相似。如果A，B特征值相同，B不能相似对角化，不能推出来A,B是否相似。如果告诉你A，B相似让你找到一个P可逆矩阵使得A，B相似，只能设P为n阶矩阵根据定义式子去求出来AP=PB存在的这个P

找可逆相似矩阵两种方法

1. 如果不指定B的话，则A组成特征向量P就是可逆
2. 如果指定B的话，则用定义去求

###  公共解问题

公共解问题与双线性表示是一个问题

公共解：三种表达

1. （A下方B）X=0
2. 求出来AX=0，把X带入到B的方程组里
3. k1a1+k2a2=l1b1+l2b2，移项有解



###  特征向量求A

1. A=P对角矩阵A*P逆
2. 秩的关系求A



###  可逆矩阵P的两种理解

1. 行列式不为0
2. 线性无关的列向量

###  列向量不是特征向量的特征方程理解

$$
AC=\lambda C
$$

这个式子C不是A的特征向量但是能得到C是A属于λ的特征向量一部分，至少为R（C）个

###  两个矩阵相似充分条件

1. 两个矩阵的特征值相同（每个不同）
2. 一个可相似对角化

###  二次型

###  二次型规范标准化

两大方法

1. 可逆线性变换

   这种方法本质是配方法，配出来之后求出来C，X=CY配出来新的规范

   ==注意==：如果有平方项则正常配方，如果没有平方项则，x1=y1+y2,x2=y1-y2,x3=y3出现平方项再配方

2. 正交变换

   这种方法本质上是求出来矩阵A特征值，然后特征值Y的规范化！

   这两种特点是用矩阵就用正交，不用矩阵写出来定义型就用配方

###  二次型易错题型

==很多人以为（x1+x2）方+（x2+x3)方，直接换元变成两个都是正的系数，误以为秩就是2，或者说正指数就是2，其实是不对的，这样不一定是变换的矩阵前提是可逆线性变换==

###  x1方+x2方结论

x1方+x2方=y1方+y2方

###  线性变换后二次型矩阵发生的变化（求正交矩阵）

如果X=CY经过线性变换使得X的二次型变成Y的二次型，那么这个二次型矩阵是经历了合同变换，CtAC=B;（==这个是二次型矩阵==）！

==如果要求出来这个C==，需要根据相似理论分别求出来A，B的对角化的矩阵，然后去导

<img src="./数学笔记.assets/image-20250730114120734.png" alt="image-20250730114120734" style="zoom:33%;" />

###  二次型最值问题

二次型最值问题，一般来说就是取X=QY，找出来特征值，最大值就是特征值的最大值，最小值就是特征值的最小值

###  求合同矩阵

这个问题我们一般用可逆线性变换来求出来

因为可逆线性变换后的矩阵都是合同的，那么这个可逆线性变换的矩阵就是合同矩阵

**如果是A，B合同求合同变换矩阵**

这种问题一般是用第三方的对角矩阵合同，A合同于对角，B合同于对角，则列出来等式求出来合同矩阵![image-20250821140047790-1756462027262-2](./数学笔记.assets/image-20250821140047790-1756462027262-2.png)

###  合同小结论

**实对称前提下**相似必合同，合同不一定相似！！！

正负惯性指数来判断两个矩阵是否合同

对称的合同矩阵一定是对称，不对称的一定和不对称的合同

###  正交变换注意事项

正交变换前后的矩阵一定是相似且合同的

正交变换也可以把矩阵转位对角矩阵（==前提是这个正交矩阵必须由特征向量构成，否则不可以转位对角矩阵==）

###  把二次型转为位规范性

要么就是可逆线性变换，要么就是正交变换

###  变换定理

在二次型的变换里，经过变换之后至少能得到矩阵的一个合同定理

## 概率论

###  独立的结论

1. 独立没有传递性
2. 独立没有包含关系

### 概率变化

已知结果会导致概率变化

### 概率中最大最小值的处理

我们一般都把他转成与事件！

### 遇到指数函数

凑正态分布函数

### 二维正态分布结论

边缘分布也是呈现正态分布函数的

### 常见分布可加性

二项分布可加性

泊松分布可加性

正态分布可加性

指数分布可加性（min(X，Y)~E(f1+f2))

### 分布函数的分布

如果一个x的分布函数是单调递且连续，那么这个分布函数的分布函数是二项分布，Fx服从U（0,1)分布，F（F（X））=u在（0,1）区间

### 均匀分布的棍子截取问题

<img src="./数学笔记.assets/image-20250821140051989-1756462027262-3.png" alt="image-20250821140051989-1756462027262-3" style="zoom:33%;" /><img src="./数学笔记.assets/image-20250821140050123-1756462027262-1.png" alt="image-20250821140050123-1756462027262-1" style="zoom:33%;" /><img src="./数学笔记.assets/image-20250821140047790-1756462027262-2.png" alt="image-20250821140047790-1756462027262-2" style="zoom:33%;" />

如果是截取取最短的一次就是用X=min(l，l-y)

==注意这里不能用最小公式，因为括号里头的变量不独立==	

然后如果是截取两次那么就是一个几何概率问题 ==注意截取的时候我们把坐标当做一个截取点，如果是长度反而不好理解和计算==



### 条件分布



---

#### 1. 定义直观理解

条件期望是“已知 $Y$，对 $X$ 的最佳预测值”。

* **直观比喻**：我知道今天的天气（Y），想估计去的人数（X）。
* 那么 $E[X|Y=y]$ 就是：在天气固定为 $y$ 的条件下，人数的平均值。

---

#### 2. 离散情形

如果 $(X,Y)$ 是离散型的，定义为：

$$
E[X|Y=y] = \sum_x x \, P(X=x \mid Y=y).
$$

也就是先算条件分布，再加权平均。

**例子**：
设 $(X,Y)$ 的联合分布如下：

| X\Y  | 1    | 2    |
| ---- | ---- | ---- |
| 0    | 0.1  | 0.2  |
| 1    | 0.3  | 0.4  |

比如 $E[X|Y=1]$：

* $P(Y=1)=0.1+0.3=0.4$
* $P(X=0|Y=1)=0.1/0.4=0.25,\;P(X=1|Y=1)=0.75$
* 所以 $E[X|Y=1]=0\cdot0.25+1\cdot0.75=0.75$。

---

#### 3. 连续情形

若 $(X,Y)$ 有联合密度 $f_{X,Y}(x,y)$，边缘密度 $f_Y(y)$，则：

$$
E[X|Y=y] = \int_{-\infty}^\infty x \cdot f_{X|Y}(x|y)\, dx
= \frac{\int x f_{X,Y}(x,y)\, dx}{f_Y(y)}.
$$

---

#### 4. 重要结论/性质

* **线性性质**： $E[aX+b|Y] = aE[X|Y]+b$。
* **函数化**： $E[g(Y)|Y]=g(Y)$。
* **塔式性质（迭代期望）**： $E[E[X|Y]]=E[X]$。
* **最佳预测**： 对已知 $Y$，$E[X|Y]$ 是最小化均方误差的最优估计。

---

#### 5. 特殊情况（常考/常用）

1. **独立性**：若 $X \perp Y$，则 $E[X|Y]=E[X]$。

2. **线性高斯情形**：若 $(X,Y)$ 服从二维正态，

   $$
   E[X|Y=y]=E[X]+\frac{\mathrm{Cov}(X,Y)}{\mathrm{Var}(Y)}(y-E[Y]).
   $$

   （这就是线性回归、卡尔曼滤波的核心）

---

#### 6. 举例

例：$X,Y$ 联合密度在单位正方形 $[0,1]\times[0,1]$ 上均匀分布。

* $f_{X,Y}(x,y)=1$。

* 边缘 $f_Y(y)=\int_0^1 1 dx=1$。

* 所以 $f_{X|Y}(x|y)=1, \; 0<x<1$。

* 因此

  $$
  E[X|Y=y]=\int_0^1 x \, dx = \tfrac{1}{2}.
  $$

说明：虽然知道了 $Y$，但因为独立，条件期望还是常数 $1/2$。

---

✅ 总结一句话：
条件期望的**计算套路**就是：

1. 先写出条件分布（概率或密度）；
2. 再对 $X$ 做加权平均。
   核心意义是 **“已知条件下对随机变量的最佳均方预测”**。

---

好 👍 你说的其实是条件期望

$$
E[Y \mid Y>1],
$$

也就是 **在事件 $\{Y>1\}$ 下的 $Y$ 的均值**。

---

#### 通用公式（连续型）

对连续随机变量 $Y$，条件期望定义为：

$$
E[Y \mid Y>1] = \frac{\int_{1}^{\infty} y f_Y(y)\, dy}{P(Y>1)},
$$

其中 $f_Y(y)$ 是 $Y$ 的概率密度函数。

---

#### 步骤

1. **算分母（条件概率）**：

   $$
   P(Y>1) = \int_{1}^{\infty} f_Y(y)\,dy.
   $$

2. **算分子（条件下的期望积分）**：

   $$
   \int_{1}^{\infty} y f_Y(y)\, dy.
   $$

3. **两者相除**：

   $$
   E[Y|Y>1] = \frac{\int_{1}^{\infty} y f_Y(y)\, dy}{\int_{1}^{\infty} f_Y(y)\, dy}.
   $$

---

#### 举例

* 若 $Y \sim \text{Uniform}(0,2)$，那么 $f_Y(y)=\tfrac{1}{2},\,0<y<2$。

  * $P(Y>1)=\int_{1}^2 \tfrac{1}{2} dy = \tfrac{1}{2}.$

  * 分子 $\int_{1}^2 y \tfrac{1}{2} dy = \tfrac{1}{2}\cdot \tfrac{3}{2} = \tfrac{3}{4}.$

  * 所以

    $$
    E[Y|Y>1] = \frac{3/4}{1/2}=1.5.
    $$

---

✅ 总结：
你要算的条件期望就是 **分子“带权积分”除以分母概率**。具体数值要看你 $Y$ 的分布是什么。

要不要你把 \*\*$Y$ 的分布（比如正态、指数、均匀等）\*\*告诉我，我帮你把公式算成具体结果？

好问题 👍。条件期望 $E[X|Y]$ 在概率论里是非常重要的概念（数理统计、信号估计、机器学习里到处用到）。我给你分层次解释，并告诉你不同情况下怎么算。

### 遇到最大整数

则用最大整数定理

### 换元法之后fv的范围

知道了联合概率密度之后用负无穷到正无穷fx,y积分求出来

1. 首先先对v的范围进行分解
2. 然后再对u等于什么v，确定上下限

### 分布函数讨论定理

如果一维讨论一个变量

如果二维讨论两个变量

### 球与盒子模型

一般就是安排盒子找盒子的可能

### 看到随机变量组合就一定想起联合分布

如果在P{里遇到X，Y的限定}那么一定就是确定D的范围

如果在E里头遇到（X，Y的组合）就一点是联合分布

### 长度就是均匀分布

比如在（0,1）区间任何一点的截取长度为X，那么X服从均匀分布U（0,1）因为坐标是X，概率密度是1那么1*X就是长度了

### 离散联合分布律

### 判断独立

必须要求每一项概率必须不为0而且秩为1

### 条件绝对值E(|x-y|)

遇到条件绝对值首先需要把他转化为E(max(x,y)-min(x,y))，然后用最大值最小值分布函数求概率密度，然后接下来大概率会用到伽马函数，用阶乘性质就好了

### 依概率收敛

==平均值依概率收敛到期望==  ==频率依概率收敛于概率==

------

#### 定义

在概率论中，如果有一列随机变量 $\{X_n\}$，它 **依概率收敛** 到一个常数或随机变量 $X$，记作

$X_n \xrightarrow{p} X,$

意思是：对任意的 $\varepsilon > 0$，有

$\lim_{n \to \infty} P\left( |X_n - X| > \varepsilon \right) = 0。$

直观理解：当 $n$ 越来越大时，随机变量 $X_n$ 偏离 $X$ 的概率会越来越小。也就是说，$X_n$ 会“越来越可能”接近 $X$。

------

#### 举个例子

#### 例子 1：抛硬币取样均值

设 $X_1, X_2, \dots$ 是独立同分布的伯努利随机变量，每次抛硬币正面为 1，反面为 0，概率 $P(X_i = 1) = 0.5$。

定义样本均值：

$\bar{X}_n = \frac{1}{n}\sum_{i=1}^n X_i。$

根据 **大数定律**，当 $n \to \infty$ 时，$\bar{X}_n$ 依概率收敛到期望值 $0.5$：

$\bar{X}_n \xrightarrow{p} 0.5。$

直观上：随着抛硬币次数越来越多，正反面比例越来越接近 $1/2$。

------

#### 例子 2：带噪声的序列

令随机变量序列：

其中 $Z$ 是一个有界的随机变量（比如 $Z \sim N(0,1)$）。

那么

$P(|X_n - 1| > \varepsilon) = P\!\left(\frac{|Z|}{n} > \varepsilon \right) = P(|Z| > n\varepsilon)。$

由于当 $n \to \infty$ 时，$n\varepsilon \to \infty$，所以这个概率趋向于 0。
 因此：

$X_n \xrightarrow{p} 1。$

------

#### 小结

- **依概率收敛** = “随机变量序列越来越可能靠近某个值”。
- 常见情形：大数定律中的样本均值收敛到总体期望。

------

要不要我帮你画一个直观的概率图（比如抛硬币均值的分布随 $n$ 增大越来越集中在 0.5）？

### 期望

遇到里边的平方我们喜欢用D+E外平方解决

### 偏导问题

如果fx=f（x,y)dy这种时候，是x轴切，x表示y

如果fy=f(x，y)dx是y轴切，y表示x

### 概率技巧

在分布函数里面积就是概率

### 假设检验与区间估计的理解

好 👍，我来帮你系统梳理一下 **假设检验与区间估计**，它们其实是统计推断的两大核心方法。

------

#### 一、区间估计（Interval Estimation）

##### 1. 定义

区间估计是用样本信息来估计总体参数，并给出一个“区间范围”，在一定置信水平下，这个区间覆盖总体参数的概率较高。

##### 2. 基本形式

如果总体参数是 $\theta$，我们构造一个随机区间

$(L(X_1,\dots,X_n), \, U(X_1,\dots,X_n))$

满足

$P\{ L \leq \theta \leq U \} = 1 - \alpha,$

其中 $1-\alpha$ 就是置信水平（confidence level），常见取 $95\%$ 或 $99\%$。

- **区间长度**：反映精确程度，样本量大 → 区间更窄。
- **置信水平**：反映可靠性，置信度高 → 区间更宽。

##### 3. 举例

样本来自 $N(\mu, \sigma^2)$，$\sigma^2$ 已知。
 则 $\bar{X}\sim N(\mu,\sigma^2/n)$。
 构造置信区间：

$\mu \in \left( \bar{X} - z_{\alpha/2}\frac{\sigma}{\sqrt{n}}, \, \bar{X} + z_{\alpha/2}\frac{\sigma}{\sqrt{n}} \right).$

------

#### 二、假设检验（Hypothesis Testing）

##### 1. 定义

假设检验是对总体参数 $\theta$ 的假设（通常有两种对立假设）进行检验，利用样本来决定是否接受或拒绝原假设。

##### 2. 两类假设

- **原假设 $H_0$**：默认成立的假设，例如“$\mu=\mu_0$”
- **备择假设 $H_1$**：与原假设对立的假设，例如“$\mu\neq\mu_0$”

##### 3. 两类错误

- 第一类错误（Type I error）：拒绝了正确的 $H_0$，概率记作 $\alpha$（显著性水平）。
- 第二类错误（Type II error）：接受了错误的 $H_0$，概率记作 $\beta$。

通常我们固定 $\alpha$（如 0.05），并尽量减小 $\beta$。

##### 4. 基本步骤

1. 提出假设：$H_0$ 与 $H_1$。
2. 选择显著性水平 $\alpha$。
3. 构造检验统计量（通常利用已知分布）。
4. 确定拒绝域。
5. 根据样本观测值落在拒绝域与否，决定是否拒绝 $H_0$。

##### 5. 举例

已知总体 $N(\mu, \sigma^2)$，$\sigma^2$ 已知。
 检验 $H_0: \mu=\mu_0$ vs $H_1: \mu\neq \mu_0$。

- 检验统计量：

  Z=Xˉ−μ0σ/n∼N(0,1).Z = \frac{\bar{X}-\mu_0}{\sigma/\sqrt{n}} \sim N(0,1).

- 拒绝域：
   $|Z| > z_{\alpha/2}$。

如果算出来的 $Z$ 超过临界值，就拒绝 $H_0$。

------

### 三、两者的联系与区别

| 对比点   | 区间估计                       | 假设检验           |
| -------- | ------------------------------ | ------------------ |
| 目标     | 给出参数的可能范围             | 判断假设是否成立   |
| 结果     | 一个区间（带置信度）           | 接受/拒绝原假设    |
| 核心思想 | 构造置信区间覆盖参数           | 构造拒绝域排除假设 |
| 关系     | 区间估计与双侧假设检验常常等价 | 检验能反推出区间   |

**联系举例**：
 如果 95% 置信区间是 $(1.2, 2.5)$，
 要检验 $H_0:\mu=3$，显著性水平 0.05，
 因为 3 不在区间内 → 拒绝 $H_0$。

------

✅ 总结：

- **区间估计**：告诉你“参数可能落在什么范围内”。
- **假设检验**：告诉你“数据是否支持某个假设”。
- 两者都是基于样本分布构造的统计推断方法，常常互相转化。

------

### 常用结论（重点掌握）

==我们做题一般是用检验法和区间法==

- 设 $\alpha=0.05$，$z_{0.05}=1.645$，样本 $\bar X = 10.3$，$\sigma/\sqrt{n}=0.1$，$\mu_0=10$。

- **检验法**：
  $$
  Z = \frac{10.3-10}{0.1}=3 > 1.645 \quad \Rightarrow \quad 拒绝 H_0。
  $$

- **区间法**：
  $$
  \mu \in (10.3-1.645\times0.1, \infty)=(10.135, \infty)。
  $$
  因为 $\mu_0=10$ 不在区间内，所以拒绝 $H_0$。

结果完全一致 ✅。

#### 双侧检验

##### 方差已知

![image-20250829205853284](./数学笔记.assets/image-20250829205853284-1756472335904-1.png)

##### 方差未知

![image-20250829205911777](./数学笔记.assets/image-20250829205911777-1756472353078-3.png)

#### 单边检验

##### 方差已知

###### 右侧检验

![image-20250829205923516](./数学笔记.assets/image-20250829205923516-1756472365040-5.png)

###### 左侧检验

改成+，左区间

##### 方差未知



###### 右侧检验

![image-20250829205933044](./数学笔记.assets/image-20250829205933044.png)

###### 左侧检验

改成+，左区间

#### 两类错误的定义

这个的理解一般要掌握两方面

**弃真**（a概率）：

1. H0为真但是拒绝了H0
2. 在拒绝率的概率

**取伪（**b概率）

1. H0为假，接受H0
2. 在接受域的概率

### 置信区间和拒绝域的关系

他俩其实就是一回事，无非置信区间是在参数量的纬度，拒绝域是在统计量的纬度

比如你落在置信区间那么就在接受域等价

在不置信区间就在拒绝域



拒绝域是从 **统计量出发** 得到的判别规则。

单侧置信区间是从 **参数出发** 得到的范围。

它们没有矛盾，而是**等价的**：
$$
H_0 \text{被拒绝} \quad \Longleftrightarrow \quad \mu_0 \notin \text{置信区间}.
$$

### 假设的选择

我们一般把**要检验的变成备选假设**，这个是因为如果错了那么就只会犯弃真概率，弃真概率又叫做a概率，他是又不可信水平a控制的（显著性水平）这样对统计者来说更容易控制，将错误影响降到最小。

#### 关于知乎上的理解

https://zhuanlan.zhihu.com/p/86178674?share_code=1e9XIRfujLGaA&utm_psn=1944867300957201437

### 不变性原理

不变形原理就是求出来的参数，直接带入

==矩估计不具有不变形==

==最大似然估计具有不变形==

参数不变性：有时候就是让你的求参数的估计量，你就用E（X)=X平均值，表示参数就好了

#### 符不符合某种分布的标准

跟这个分布的期望和方差规律一样就行了

1. 期望
2. 方差

### 期望和方差的无偏估计量就是样本均值和方差

### 一致性的判断

一般一致性我们用两种方法 

==一致性一般和依概率收敛非常像==，把依概率收敛的数变成参数量本身就变成了一致性

1. 辛勤大数定律
2. 切比雪夫（**常用**）

## 高数

### 奇点

不可定义点和无定义点

件期望计算的速查表”**（离散、连续、高斯、独立情形），方便你考试/作业直接套用？

### 极限两大求法

**示例	**	

x→0limxln(1+x+xf(x))=3

分析步骤是：

1. **当 $x \to 0$ 时**，分母 $\to 0$。为了极限存在，分子必须也 $\to 0$。
    所以
   $$
   \lim_{x \to 0} \left(x+\frac{f(x)}{x}\right) = 0.
   $$
   这一步得到的不是恒等式，而是一个**极限条件**，即：当 $x$ 很小时，$x+\frac{f(x)}{x}$ 趋向 0。

------

1. 你写成 $\frac{f(x)}{x}=-x$，再推 $f(x)=-x^2$，这是把“极限趋于 0”理解成了“恒等于 0”。⚠️ 这是逻辑错误。

   正确理解：
   $$
   \lim_{x \to 0}\Big(x+\frac{f(x)}{x}\Big)=0
   \quad \Longleftrightarrow \quad
   \frac{f(x)}{x} \sim -x \ \ (x\to 0),
   $$
   这里的“$\sim$”表示“同阶无穷小”，而不是严格等号。

#### 脱帽法

极限条件化为等式条件	

#### 泰勒法

泰勒展开等同等x

### 含参变量的积分

<img src="./数学笔记.assets/image-20250831093255357.png" alt="image-20250831093255357" style="zoom:33%;" />

### 拉格朗日中值定理

在这里用行列式解决，先把fx，fy这个行列式解决了，然后带入辣么大的方程
